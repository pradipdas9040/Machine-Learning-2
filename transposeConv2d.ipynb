{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Electronics and Communication Sciences Unit\n",
        "# Indian Statistical Institute, Kolkata\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3d5qaJFg76cr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Transposed Convolution**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "![start.png](http://www.mit.edu/~jessicav/6.S198/Blog_Post/imgs/checkerboard_explanation.gif)\n",
        "\n",
        "https://distill.pub/2016/deconv-checkerboard/\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "The CNN layers we have seen so far,\n",
        "such as convolutional layers  and pooling layers,\n",
        "typically reduce (downsample) the spatial dimensions (height and width) of the input,\n",
        "or keep them unchanged.\n",
        "In semantic segmentation\n",
        "that classifies at pixel-level,\n",
        "it will be convenient if\n",
        "the spatial dimensions of the\n",
        "input and output are the same.\n",
        "For example,\n",
        "the channel dimension at one output pixel \n",
        "can hold the classification results\n",
        "for the input pixel at the same spatial position.\n",
        "\n",
        "\n",
        "To achieve this, especially after \n",
        "the spatial dimensions are reduced by CNN layers,\n",
        "we can use another type\n",
        "of CNN layers\n",
        "that can increase (upsample) the spatial dimensions\n",
        "of intermediate feature maps.\n",
        "In this section,\n",
        "we will introduce \n",
        "*transposed convolution*, which is also called *fractionally-strided convolution* :cite:`Dumoulin.Visin.2016`, \n",
        "for reversing downsampling operations\n",
        "by the convolution.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Basic Operation\n",
        "\n",
        "Ignoring channels for now,\n",
        "let's begin with\n",
        "the basic transposed convolution operation\n",
        "with stride of 1 and no padding.\n",
        "Suppose that\n",
        "we are given a \n",
        "$n_h \\times n_w$ input tensor\n",
        "and a $k_h \\times k_w$ kernel.\n",
        "Sliding the kernel window with stride of 1\n",
        "for $n_w$ times in each row\n",
        "and $n_h$ times in each column\n",
        "yields \n",
        "a total of $n_h n_w$ intermediate results.\n",
        "Each intermediate result is\n",
        "a $(n_h + k_h - 1) \\times (n_w + k_w - 1)$\n",
        "tensor that are initialized as zeros.\n",
        "To compute each intermediate tensor,\n",
        "each element in the input tensor\n",
        "is multiplied by the kernel\n",
        "so that the resulting $k_h \\times k_w$ tensor\n",
        "replaces a portion in\n",
        "each intermediate tensor.\n",
        "Note that\n",
        "the position of the replaced portion in each\n",
        "intermediate tensor corresponds to the position of the element\n",
        "in the input tensor used for the computation.\n",
        "In the end, all the intermediate results\n",
        "are summed over to produce the output.\n",
        "\n",
        "As an example,\n",
        ":numref:`fig_trans_conv` illustrates\n",
        "how transposed convolution with a $2\\times 2$ kernel is computed for a $2\\times 2$ input tensor.\n",
        "\n",
        "\n",
        "![Transposed convolution with a $2\\times 2$ kernel. The shaded portions are a portion of an intermediate tensor as well as the input and kernel tensor elements used for the  computation.](http://d2l.ai/_images/trans_conv.svg)\n",
        "\n",
        "\n",
        ":label:`fig_trans_conv`\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Z4DtQohgTrMm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CASE 1: Basic\n",
        "\n",
        "![image.png](https://miro.medium.com/max/1400/1*FZ6mACe7DJLjvD3LLCn9TQ.gif)\n",
        "\n",
        "\n",
        "shows the calculation process of a transposed convolutional layer with kernel_size to be 3, and other parameters set to default. The dimensions of input (2x2) and output (4x4) could be easily recognized.\n",
        "\n",
        "Following is the by-step calculation process. As the animation shows, there are 4 steps to generate the final output.\n",
        "\n",
        "![image.png](https://miro.medium.com/max/1400/1*Blv7vr9sMAmfYTTgKCKGVw.jpeg)\n",
        "\n"
      ],
      "metadata": {
        "id": "ERFlTRDoUyEN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "input_data = torch.tensor([[[[1.,2.],[3.,4.]]]])"
      ],
      "metadata": {
        "id": "S3lFNOE1XQ18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create 2x2 input tensor\n",
        "input_data = torch.tensor([[[[1.,2.],[3.,4.]]]])\n",
        "\n",
        "# Create a TCL layer with kernel_size=3\n",
        "transConv1 = nn.ConvTranspose2d(1, 1, 3, bias=False)\n",
        "\n",
        "# Set kernel weights to be 1\n",
        "transConv1.weight.data = torch.ones(1,1,3,3)\n",
        "\n",
        "# Calculate the output\n",
        "transConv1(input_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qd7hYOyfW3iW",
        "outputId": "254e57fa-448a-496f-fb42-2884b7f2794a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[ 1.,  3.,  3.,  2.],\n",
              "          [ 4., 10., 10.,  6.],\n",
              "          [ 4., 10., 10.,  6.],\n",
              "          [ 3.,  7.,  7.,  4.]]]], grad_fn=<ConvolutionBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Case 2: Stride\n",
        "we will change the parameter stride, leave everything else to be the same as the 1st case.\n",
        "\n",
        "The default value of stride is 1, here we set stride to be 2.\n",
        "\n",
        "![image2.png](https://miro.medium.com/max/1400/1*na8U3QpHwuAB3R9QohQC1w.gif)\n",
        "\n",
        "As you can see, after each multiplication step, the kernel matrix moves 2 steps horizontally until it hits the end, and then move 2 steps vertically and start from the beginning.\n",
        "\n",
        "Let’s see the calculation processes:\n",
        "\n",
        "![img.png](https://miro.medium.com/max/1400/1*zsqJh7WU7ARUGZ-jgvF1dw.jpeg)\n",
        "\n"
      ],
      "metadata": {
        "id": "a8mIe86-8vuH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Create a TCL layer with stride=2\n",
        "transConv2 = nn.ConvTranspose2d(1, 1, 3, stride=2, bias=False)\n",
        "# Set kernel weights to be 1\n",
        "transConv2.weight.data = torch.ones(1,1,3,3)\n",
        "# Disable gradient decent\n",
        "for w in transConv2.parameters():\n",
        "    w.requires_grad = False\n",
        "# Calculate\n",
        "transConv2(input_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RILDNLByXhke",
        "outputId": "0765a9b1-780c-4e04-f82d-ac4a69837c30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[ 1.,  1.,  3.,  2.,  2.],\n",
              "          [ 1.,  1.,  3.,  2.,  2.],\n",
              "          [ 4.,  4., 10.,  6.,  6.],\n",
              "          [ 3.,  3.,  7.,  4.,  4.],\n",
              "          [ 3.,  3.,  7.,  4.,  4.]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CASE 3: Padding\n",
        "\n",
        "We will keep building based on stride case, this time we change parameter padding to 1\n",
        "\n",
        " the padding has default value 0.\n",
        "\n",
        " ![img4.png](https://miro.medium.com/max/1400/1*4KKbju-YNsbvDSfYlIHFVg.gif)\n",
        "\n",
        " The final output, in this case, is the center 3x3 matrix. You can interpret it as, after calculation, drop the border cells of the matrix. You should be able to imagine if we set padding equal 2, the result would be the center cell (1x1).\n",
        "\n",
        " ![img5.png](https://miro.medium.com/max/1400/1*HokEeAWSt_rwzREUdyFWCQ.jpeg)\n",
        "\n",
        " as you can see, it is almost identical to above. The only difference is we ‘removed’ the outer cells."
      ],
      "metadata": {
        "id": "N8fuG1YI94Cz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Create a TCL layer with stride=2, padding=1\n",
        "transConv3 = nn.ConvTranspose2d(1, 1, 3, stride=2, padding=2, bias=False)\n",
        "# Set kernel weights to be 1\n",
        "transConv3.weight.data = torch.ones(1,1,3,3)\n",
        "# Disable gradient decent\n",
        "for w in transConv3.parameters():\n",
        "    w.requires_grad = False\n",
        "# Calculate\n",
        "transConv3(input_data)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dccw2O4fWXXx",
        "outputId": "4506e884-3925-4e37-8e07-997a65403b99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[10.]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CASE 4: Output Padding\n",
        "\n",
        "we have another kind of padding. Their difference is simple:\n",
        "Output Padding adds cells to one side of the output, while padding removes cells from both sides of the output.\n",
        "\n",
        "![img6.png](https://miro.medium.com/max/1400/1*8KQDwfmCJpBZAS4BWQAHFg.gif)\n",
        "\n",
        "In this case, we set parameter output_padding to be 1 (default is 0), and stride to be 2. As shown in figure 7, one side of the output matrix has been added cells, which has value 0.\n",
        "\n",
        "calculation steps:\n",
        "\n",
        "![img8.png](https://miro.medium.com/max/1400/1*l-TG8mr4E2QdPBRy0pKmZA.jpeg)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "g_26KImr-x3F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Create a TCL layer with stride=2, output_padding=1\n",
        "transConv4 = nn.ConvTranspose2d(1, 1, 4, stride=3, output_padding=2, bias=False)\n",
        "# Set kernel weights to be 1\n",
        "transConv4.weight.data = torch.ones(1,1,3,3)\n",
        "# # Disable gradient decent\n",
        "# for w in transConv4.parameters():\n",
        "#     w.requires_grad = False\n",
        "# Calculate\n",
        "transConv4(input_data)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmYi90cm-z9k",
        "outputId": "613949d7-a028-4861-bee1-cef90d3f25b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[1., 1., 1., 2., 2., 2., 0., 0.],\n",
              "          [1., 1., 1., 2., 2., 2., 0., 0.],\n",
              "          [1., 1., 1., 2., 2., 2., 0., 0.],\n",
              "          [3., 3., 3., 4., 4., 4., 0., 0.],\n",
              "          [3., 3., 3., 4., 4., 4., 0., 0.],\n",
              "          [3., 3., 3., 4., 4., 4., 0., 0.],\n",
              "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "          [0., 0., 0., 0., 0., 0., 0., 0.]]]], grad_fn=<ConvolutionBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CASE 5: Dilation\n",
        "\n",
        "Dilation influence the structure of the kernel matrix.\n",
        "\n",
        "The PyTorch documentation puts,\n",
        "\n",
        "    dilation controls the spacing between the kernel points;\n",
        "\n",
        "look at figure, you might be able to understand it. To make things easier, let’s use the 2x2 kernel in this example. \n",
        "\n",
        "![img9.png](https://miro.medium.com/max/1400/1*dCr3pn2WQ_yv_Lt6Litnvw.jpeg)\n",
        "\n",
        "Above is what the kernel matrix looks like with different dilation values. Basically, if dilation value is n, then the kernel matrix will be interjected n-1 cells filled with 0. At this point, it should not be hard to imagine the same transformation for bigger kernel matrices. And the rest calculation remains the same as before, as shown in figure \n",
        "\n",
        "![img10.png](https://miro.medium.com/max/1400/1*XJpA0zdmc80seyqZODSF7Q.gif)\n",
        "\n",
        "Below is the calculation steps:\n",
        "\n",
        "![img11.png](https://miro.medium.com/max/1400/1*0FL5feyXLuewR3duDj6vww.jpeg)\n",
        "\n"
      ],
      "metadata": {
        "id": "weaHAuOf_qOa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Create a TCL layer with kernel_size=2, stride=2, dilation=2\n",
        "transConv5 = nn.ConvTranspose2d(1, 1, 2, stride=2, dilation=2, bias=False)\n",
        "# Set kernel weights to be 1\n",
        "transConv5.weight.data = torch.ones(1,1,2,2)\n",
        "# Disable gradient decent\n",
        "for w in transConv5.parameters():\n",
        "    w.requires_grad = False\n",
        "# Calculate\n",
        "transConv5(input_data)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kuRYLizf_uJc",
        "outputId": "e013a232-b9d0-42be-a8ba-56adf6785e88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[ 1.,  0.,  3.,  0.,  2.],\n",
              "          [ 0.,  0.,  0.,  0.,  0.],\n",
              "          [ 4.,  0., 10.,  0.,  6.],\n",
              "          [ 0.,  0.,  0.,  0.,  0.],\n",
              "          [ 3.,  0.,  7.,  0.,  4.]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FORMULA: Math behind the output shape\n",
        "\n",
        "The of the formula for output size is:\n",
        "\n",
        "![img12.png](https://miro.medium.com/max/1400/1*RRJw1colfm5tqfJfFB_1KA.png)\n",
        "\n",
        "Where n is the output size (n x n matrix), m is the input size (m x m matrix). Besides, there are 5 parameters in the formula: K is the kernel size, S is the stride value, P is the padding value, D is the dilation value and P_out is the output_padding value.\n",
        "\n",
        "## Step by Step:\n",
        "\n",
        "**Only consider S (stride) and K (kernel size)**\n",
        "\n",
        "Because the input size is m, so we have m*m steps of calculation. But we really only need to consider the first m steps, since the first m step would fix the width of the output matrix.\n",
        "\n",
        "We can imagine the output progressively grow as the calculation proceeds\n",
        "\n",
        "1. In the 1st step, the output size is K.\n",
        "2.     In the 2nd step, the intermedia matrix shift by S, so the output size is K + S.\n",
        "3. In the 3rd step, the intermedia matrix shift by S, so the output size is K + 2S.\n",
        "4. In the m-th step, the intermedia matrix shift by S, so the output size is K + (m-1)S.\n",
        "\n",
        "Therefore, if we only consider S and K, the formula would be:\n",
        "\n",
        "![img13.png](https://miro.medium.com/max/1400/1*sZUe9JH7M7INAklIYSdbwQ.png)\n",
        "\n",
        "______________________________________________________________________________\n",
        "## Very close connection with the matrix transposition you can check here\n",
        "\n",
        "https://colab.research.google.com/github/d2l-ai/d2l-pytorch-colab/blob/master/chapter_computer-vision/transposed-conv.ipynb#scrollTo=n4Us83L5U3Tc\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "## Problem with Deconvolution/transposed convolution : Checkerboard Artifacts \n",
        "https://distill.pub/2016/deconv-checkerboard/\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "alkQhH4EBcGM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reference\n",
        "\n",
        "https://medium.com/analytics-vidhya/demystify-transposed-convolutional-layers-6f7b61485454\n",
        "\n",
        "https://distill.pub/2016/deconv-checkerboard/\n",
        "\n",
        "http://www.mit.edu/~jessicav/6.S198/Blog_Post/ProceduralGeneration.html\n",
        "\n",
        "https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html\n",
        "\n"
      ],
      "metadata": {
        "id": "EqGv42tADSK3"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zG8oH-63EAJl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}