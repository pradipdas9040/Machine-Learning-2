{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hidden Markov Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Hidden Markov Model (HMM) is a statistical model used to represent systems where the state of the system is not directly observable (hidden), but outputs or observations influenced by these states are visible. HMM is widely used in fields like natural language processing, speech recognition, and bioinformatics.\n",
    "\n",
    "<img src=\"https://www.researchgate.net/profile/Jan-Bulla-2/publication/24115579/figure/fig2/AS:669552555872262@1536645177600/Basic-structure-of-a-Hidden-Markov-Model.png\" width=\"450\">\n",
    "\n",
    "#### Components of an HMM\n",
    "\n",
    "1. States $(S)$\n",
    "    - A finite set of hidden states $S = \\{S_1, S_2, ..., S_n\\} \\in \\{1,2,...,m\\}$.\n",
    "    - The system transitions between these states over time.\n",
    "\n",
    "2. Observations $(O)$\n",
    "    - A finite set of observable symbols $O=\\{X_1, X_2, ...,X_n\\} \\in \\mathcal{X}$.\n",
    "    - These are emitted by the states.\n",
    "\n",
    "3. Transition Probabilities $(A)$\n",
    "    - Matrix $A=[a_{ij}]$, where $a_{ij}=P(S_k=j|S_{k-1}=i)$ for all $i,j\\in [m]$.\n",
    "\n",
    "4. Emission Probabilities $(E)$\n",
    "    - Matrix $E=[\\mathcal{E}_i(x)]$, where $\\mathcal{E}_i(x)=P(X_k=x|S_k=i)$ for all $i\\in [m]$ and $x\\in \\mathcal{X}$.\n",
    "\n",
    "5. Initial State Probabilities $(\\pi)$\n",
    "    - Vector $\\pi=[\\pi_i]$, where $\\pi_i=P(S_1=i)$ for all $i\\in [m]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assumptions\n",
    "1. Markov Property:\n",
    "    - The current state depends only on the previous state: \n",
    "$$\n",
    "P(S_t|S_{t-1}, S_{t-2}, ..., S_1)=P(S_t|S_{t-1})\n",
    "$$\n",
    "2. Observation Independence:\n",
    "    - The observation at time $t$ depends only on the current state: \n",
    "$$\n",
    "P(X_t|S_t, S_{t-1}, ..., S_1)=P(X_t|S_t)\n",
    "$$\n",
    "\n",
    "#### Three Fundamental Problem\n",
    "\n",
    "1. **Likelihood:** Given an HMM $\\lambda = (A,E, \\pi)$ and an observation sequence $O$, determine the likelihood $P(O|\\lambda)$\n",
    "\n",
    "2. **Decoding (Finding the Best State Sequence):** Given an observation sequence $O$ and an HMM $\\lambda =(A,E, \\pi)$, discover the best hidden state sequence $Q=\\{S_1, S_2, .., S_t\\}$ that explains the observations $O$.\n",
    "\n",
    "3. **Learning (Parameter Estimation):** Given an observation sequence $O$ and the set of states in the HMM, learn the HMM parameters $A, E$ and $\\pi$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Likelihood Computation: The Forward Algorithm\n",
    "\n",
    "- Given an HMM $\\lambda = (A,E, \\pi)$ and an observation sequence $O$, determine the likelihood $P(O|\\lambda)$. \n",
    "\n",
    "For a particular hidden state sequence $Q = s_1,s_2,...,s_T$ and an observation sequence $O = x_1,x_2,...,x_T$ , the likelihood of the observation sequence is\n",
    "$$\n",
    "P(O|Q)=\\Pi_{i=1}^TP(x_i|s_i)\n",
    "$$\n",
    "\n",
    "But of course, we don’t actually know what the hidden state sequence was. We’ll need to compute the probability of observed sequence $O$ instead by summing over all possible state sequences, weighted by their probability. First, let’s compute the joint probability of being in a particular state sequence $Q$ and generating a particular sequence $O$ of observed events In general, this is\n",
    "$$\n",
    "P(O,Q) = P(O|Q)\\times P(Q) = \\Pi_{i=1}^TP(x_i|s_i) \\times \\Pi_{i=1}^TP(s_i | s_{i-1})\n",
    "$$\n",
    "\n",
    "Now that we know how to compute the joint probability of the observations with a particular hidden state sequence, we can compute the total probability of the observations just by summing over all possible hidden state sequences:\n",
    "$$\n",
    "P(O)=\\sum_{Q}P(O,Q)=\\sum_{Q} P(O|Q)P(Q)\n",
    "$$\n",
    "\n",
    "For an HMM with $N$ hidden states and an observation sequence of $T$ observations, there are $N^T$ possible hidden sequences. For real tasks, where $N$ and $T$ are both large, $N^T$ is a very large number, so we cannot compute the total observation likelihood by computing a separate observation likelihood for each hidden state sequence and then summing them.\n",
    "\n",
    "Instead of using such an extremely exponential algorithm, we use an efficient $O(N^2T)$ algorithm called the forward algorithm. The forward algorithm is a kind forward algorithm of dynamic programming algorithm, that is, an algorithm that uses a table to store intermediate values as it builds up the probability of the observation sequence. The forward algorithm computes the observation probability by summing over the probabilities of all possible hidden state paths that could generate the observation sequence, but it does so efficiently by implicitly folding each of these paths into a\n",
    "single forward trellis.\n",
    "\n",
    "Each cell of the forward algorithm trellis $\\alpha_t(j)$ represents the probability of being in state $j$ after seeing the first $t$ observations, given the automaton $\\lambda$. The value of each cell $\\alpha_t(j)$ is computed by summing over the probabilities of every path that could lead us to this cell. Formally, each cell expresses the following probability:\n",
    "$$\n",
    "\\alpha_t(j)=P(x_1,x_2,...,x_t, s_t=j|\\lambda)\n",
    "$$\n",
    "\n",
    "Here, $s_t = j$ means “the $t^{th}$ state in the sequence of states is state $j$”. We compute this probability $\\alpha_t(j)$ by summing over the extensions of all the paths that lead to the current cell. For a given state $s_j$ at time $t$, the value $α_t(j)$ is computed as\n",
    "$$\n",
    "\\alpha_t(j)=\\sum_{i=1}^m\\alpha_{t-1}(i)a_{ij}\\mathcal{E}_i(x_{t})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decoding\n",
    "\n",
    "\n",
    "- Given as input an HMM $\\lambda = (A,E,\\pi)$ and a sequence of observations $O = x_1,x_2,...,x_T$ , find the most probable sequence of states $Q = s_1s_2s_3 ...s_T$\n",
    "\n",
    "The Viterbi algorithm is one of the most commonly used decoding methods for Hidden Markov Models (HMMs). Similar to the forward algorithm, it leverages a dynamic programming trellis to efficiently compute the optimal sequence.\n",
    "\n",
    "Each cell $v_t(j)$, represents the probability that the HMM is in state $j$ after processing the first $t$ observations and traversing the most likely sequence of states $s_1, s_2,...,s_{t-1}$ , given the model $\\lambda$. This probability is computed recursively by determining the most probable path to that cell. Essentially, each cell captures the likelihood of arriving at a specific state via the optimal path.\n",
    "\n",
    "$$\n",
    "v_t(j) = \\max_{s_1,..,s_{t-1}}P(s_1,..s_{t-1},x_1,...,x_t, s_t=j|\\lambda)\n",
    "$$\n",
    "\n",
    "$v_t(j)$ is computed as\n",
    "$$\n",
    "v_t(j)=\\max_{i=1,..,m} v_{t-1}(i)a_{ij}\\mathcal{E}_i(x_t)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning\n",
    "\n",
    "- Given an observation sequence $O$ and the set of possible states in the HMM, the goal is to estimate the HMM parameters $A, E$ and $\\pi$.\n",
    "\n",
    "The standard algorithm for HMM training is the Baum-Welch Algorithm (a special case of the Expectation-Maximization algorithm).\n",
    "\n",
    "\n",
    "1. Forward probability: \n",
    "$$\n",
    "\\alpha_t(i)=P(x_1,x_2,...x_t, s_t=i|\\lambda)\n",
    "$$\n",
    "\n",
    "2. Backward probability: Probability of observing the sequence $x_{t+1}, x_{t+2},...,x_T$ given that we are in stste $j$ at time $t$.\n",
    "$$\n",
    "\\beta_t(j) = P(x_{t+1}, x_{t+2},...,x_T|s_t=j,\\lambda)\n",
    "$$\n",
    "\n",
    "3. The probability that we are in state $i$ at time $t$ given observing sequence $O=\\{x_{1}, x_{2},...,x_T\\}$.\n",
    "$$\n",
    "\\gamma_t(i) = P(s_t=i|O,\\lambda) \n",
    "$$\n",
    "\n",
    "<img src=\"https://miro.medium.com/v2/resize:fit:640/format:webp/1*n91Dcd8QRiYu3rGlwMVXTA.png\" width=\"450\">\n",
    "\n",
    "Let define a probability $\\xi_t(i,j)$ as the probability of state $i$ at time $t$ and state $j$ at time $t+1$ givent the observation $O$. i.e.,\n",
    "$$\n",
    "\\begin{split}\n",
    "\\xi_t(i,j)& =P(s_t=i,s_{t+1}=j|O,\\lambda) \\\\\n",
    "&=\\frac{P(s_t=i,s_{t+1}=j,O|\\lambda)}{P(O|\\lambda)}\\\\\n",
    "&= \\frac{\\alpha_t(i)a_{ij}\\mathcal{E_j(x_{t+1})\\beta_{t+1}(j)}}{\\sum_{i=1}^m \\sum_{j=1}^m\\alpha_t(i)a_{ij}\\mathcal{E_j(x_{t+1})\\beta_{t+1}(j)}}\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "If we sum over all $t$ then we have a number that can be treated as the expected number of times the state $i$ ever transition to state $j$. So,\n",
    "$$\n",
    "\\sum_{t=1}^{T-1}\\xi_t(i,j) = E(\\textnormal{number of transitions from state }i\\textnormal{ to state }j)\n",
    "$$\n",
    "\n",
    "$\\gamma_t(i)$ is the probability of being in stste $s_i$ at time $t$. So,\n",
    "$$\n",
    "\\gamma_t(i) = \\sum_{j=1}^m\\xi_t(i,j)\n",
    "$$\n",
    "If we sum over all $t$ then we have a number that can be treated as the expected number of times the state $i$ ever visited. So,\n",
    "$$\n",
    "\\sum_{t=1}^{T-1}\\gamma_t(i) = E(\\textnormal{number of transitions from state }i)\n",
    "$$\n",
    "\n",
    "Let, $\\bar{a}_{ij}$ and $\\bar{\\mathcal{E}}_j(x_t)$ be the maximum likelihood estimation of $a_{ij}$ and $\\mathcal{E}_j(x_t)$\n",
    "Now,\n",
    "$$\n",
    "\\begin{split}\n",
    "\\bar{a}_{ij}& =\\frac{E(\\textnormal{number of transitions from state }i\\textnormal{ to state }j)}{E(\\textnormal{number of transitions from state }i)} \\\\\n",
    "& =\\frac{\\sum_{t=1}^{T-1}\\xi_t(i,j)}{\\sum_{t=1}^{T-1}\\gamma_t(i)}\n",
    "\\end{split}\n",
    "$$\n",
    "and\n",
    "$$\n",
    "\\begin{split}\n",
    "\\bar{\\mathcal{E}}_j(x_t)& =\\frac{E(\\textnormal{number of transitions from state }i\\textnormal{ and observing symbol }k)}{E(\\textnormal{number of transitions from state }i)} \\\\\n",
    "& =\\frac{\\sum_{t=1; s.t. x_t=k}^{T-1}\\gamma_t(i)}{\\sum_{t=1}^{T-1}\\gamma_t(i)}\n",
    "\\end{split}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus,\n",
    "\n",
    "**E-step:**\n",
    "$$\n",
    "\\begin{split}\n",
    "\\xi_t(i,j) & = \\frac{\\alpha_t(i)a_{ij}\\mathcal{E_j(x_{t+1})\\beta_{t+1}(j)}}{\\sum_{i=1}^m \\sum_{j=1}^m\\alpha_t(i)a_{ij}\\mathcal{E_j(x_{t+1})\\beta_{t+1}(j)}}~~\\forall~t,i,j\\\\\n",
    "\\gamma_t(i) & = \\sum_{j=1}^m\\xi_t(i,j)~~\\forall~t,i\n",
    "\\end{split}\n",
    "$$\n",
    "**M-step:**\n",
    "$$\n",
    "\\begin{split}\n",
    "\\bar{a}_{ij}& =\\frac{\\sum_{t=1}^{T-1}\\xi_t(i,j)}{\\sum_{t=1}^{T-1}\\gamma_t(i)}\\\\\n",
    "\n",
    "\\bar{\\mathcal{E}}_j(x_t)& =\\frac{\\sum_{t=1; s.t. x_t=k}^{T-1}\\gamma_t(i)}{\\sum_{t=1}^{T-1}\\gamma_t(i)}\n",
    "\\end{split}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ref\n",
    "- https://web.stanford.edu/~jurafsky/slp3/A.pdf\n",
    "- https://ocw.mit.edu/courses/16-410-principles-of-autonomy-and-decision-making-fall-2010/resources/lecture-notes/\n",
    "- https://adeveloperdiary.com/data-science/machine-learning/derivation-and-implementation-of-baum-welch-algorithm-for-hidden-markov-model/"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
