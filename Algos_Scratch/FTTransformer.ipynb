{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25f40598",
   "metadata": {},
   "source": [
    "\n",
    "## FT-Transformer (Feature Tokenizer + Transformer)\n",
    "```plaintext[]\n",
    "Input Features  \n",
    "│  \n",
    "├─ Feature Tokenizer (Embedding Layer)  \n",
    "│  │  \n",
    "│  └─ Continuous Features → Linear Projection  \n",
    "│  └─ Categorical Features → Embedding Lookup  \n",
    "│  \n",
    "└─ Transformer Encoder (Multiple Layers)  \n",
    "   │  \n",
    "   └─ Multi-Head Self-Attention  \n",
    "   └─ Layer Normalization & Feed-Forward  \n",
    "   └─ Residual Connections  \n",
    "│  \n",
    "└─ Prediction Head (MLP for Regression/Classification)  \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4665b0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from collections import defaultdict\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from tqdm import tqdm\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c04747bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureTokenizer(nn.Module):\n",
    "    \"\"\"\n",
    "    Tokenizes both numerical and categorical features.\n",
    "    Numerical features are projected to d_model dimension.\n",
    "    Categorical features are embedded.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_numerical_features, cat_cardinalities, d_model):\n",
    "        super().__init__()\n",
    "        self.num_numerical = num_numerical_features\n",
    "        self.cat_cardinalities = cat_cardinalities\n",
    "        \n",
    "        if num_numerical_features > 0:\n",
    "            self.num_projection = nn.Linear(num_numerical_features, d_model)\n",
    "        \n",
    "        if cat_cardinalities:\n",
    "            self.cat_embeddings = nn.ModuleList([\n",
    "                nn.Embedding(cardinality, d_model) \n",
    "                for cardinality in cat_cardinalities\n",
    "            ])\n",
    "        \n",
    "        self.cls_token = nn.Parameter(torch.zeros(1, 1, d_model))\n",
    "        nn.init.normal_(self.cls_token, mean=0.0, std=0.02)\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "        \n",
    "    def forward(self, x_num, x_cat=None):\n",
    "        tokens = []\n",
    "        \n",
    "        if self.num_numerical > 0:\n",
    "            num_tokens = self.num_projection(x_num).unsqueeze(1)\n",
    "            tokens.append(num_tokens)\n",
    "        \n",
    "        if x_cat is not None and self.cat_cardinalities:\n",
    "            cat_tokens = []\n",
    "            for i, embed in enumerate(self.cat_embeddings):\n",
    "                cat_tokens.append(embed(x_cat[:, i]))\n",
    "            cat_tokens = torch.stack(cat_tokens, dim=1)\n",
    "            tokens.append(cat_tokens)\n",
    "        \n",
    "        tokens = torch.cat(tokens, dim=1)\n",
    "        cls_tokens = self.cls_token.expand(x_num.size(0), -1, -1)\n",
    "        tokens = torch.cat([cls_tokens, tokens], dim=1)\n",
    "        return self.norm(tokens)\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"\n",
    "    Standard positional encoding for transformers (Optional)\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:, :x.size(1)]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43c6318e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(module):\n",
    "    if isinstance(module, nn.Linear):\n",
    "        nn.init.kaiming_normal_(module.weight, nonlinearity='relu')\n",
    "        if module.bias is not None:\n",
    "            nn.init.zeros_(module.bias)\n",
    "\n",
    "    elif isinstance(module, nn.Embedding):\n",
    "        nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    elif isinstance(module, nn.LayerNorm):\n",
    "        nn.init.ones_(module.weight)\n",
    "        nn.init.zeros_(module.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4cc0df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FTTransformer(nn.Module):\n",
    "    \"\"\"\n",
    "    FT-Transformer for tabular data with mixed numerical and categorical features.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, preprocessor, d_model=64, nhead=4, num_layers=3,\n",
    "                 dim_feedforward=128, dropout=0.1, num_classes=None,\n",
    "                 use_pos_encoding=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            preprocessor: Fitted DataFramePreprocessor instance\n",
    "            d_model: Transformer model dimension\n",
    "            nhead: Number of attention heads\n",
    "            num_layers: Number of TransformerEncoder layers\n",
    "            dim_feedforward: Dimension of feedforward network\n",
    "            dropout: Dropout rate\n",
    "            num_classes: Number of output classes (None for regression)\n",
    "            use_pos_encoding: Whether to use positional encoding\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.preprocessor = preprocessor\n",
    "        self.use_pos_encoding = use_pos_encoding\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        # Feature tokenizer\n",
    "        self.feature_tokenizer = FeatureTokenizer(\n",
    "            num_numerical_features=len(preprocessor.num_cols),\n",
    "            cat_cardinalities=preprocessor.cat_cardinalities,\n",
    "            d_model=d_model\n",
    "        )\n",
    "\n",
    "        # Calculate total number of tokens\n",
    "        num_tokens = 1  # CLS token\n",
    "        if len(preprocessor.num_cols) > 0:\n",
    "            num_tokens += 1  # One token for all numerical features\n",
    "        if preprocessor.cat_cardinalities:\n",
    "            num_tokens += len(preprocessor.cat_cardinalities)\n",
    "\n",
    "        # Optional positional encoding\n",
    "        if self.use_pos_encoding:\n",
    "            self.pos_encoder = PositionalEncoding(d_model, max_len=num_tokens)\n",
    "\n",
    "        # Transformer encoder\n",
    "        encoder_layer = TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "        # Output head\n",
    "        if num_classes is not None:\n",
    "            self.head = nn.Linear(d_model, num_classes)  # Binary or multi-class classification\n",
    "        else:\n",
    "            self.head = nn.Linear(d_model, 1)  # Regression\n",
    "\n",
    "        # Initialize all weights\n",
    "        self.apply(init_weights)\n",
    "\n",
    "    def forward_from_processed(self, x_num, x_cat):\n",
    "        \"\"\"\n",
    "        Forward pass with already processed numerical and categorical tensors.\n",
    "        \"\"\"\n",
    "        tokens = self.feature_tokenizer(x_num, x_cat)\n",
    "\n",
    "        if self.use_pos_encoding:\n",
    "            tokens = self.pos_encoder(tokens)\n",
    "\n",
    "        encoded = self.transformer_encoder(tokens)\n",
    "        cls_output = encoded[:, 0, :]  # CLS token\n",
    "\n",
    "        output = self.head(cls_output)\n",
    "\n",
    "        # Return raw logits or regression output\n",
    "        return output\n",
    "\n",
    "    def forward(self, df):\n",
    "        \"\"\"\n",
    "        Forward pass directly from a raw DataFrame.\n",
    "        \"\"\"\n",
    "        x_num, x_cat = self.preprocessor.transform(df)\n",
    "        return self.forward_from_processed(x_num, x_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40d66cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFramePreprocessor:\n",
    "    \"\"\"\n",
    "    Preprocesses a pandas DataFrame for the FT-Transformer\n",
    "    - Identifies numerical and categorical columns\n",
    "    - Normalizes numerical features\n",
    "    - Encodes categorical features\n",
    "    - Handles missing values\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.num_cols = []\n",
    "        self.cat_cols = []\n",
    "        self.cat_cardinalities = []\n",
    "        self.num_scaler = StandardScaler()\n",
    "        self.cat_encoders = defaultdict(LabelEncoder)\n",
    "        self.fitted = False\n",
    "        \n",
    "    def fit(self, df, target_col='target'):\n",
    "        \"\"\"Identify and prepare feature processors\"\"\"\n",
    "        # Identify feature types\n",
    "        self.num_cols = df.drop(columns=[target_col])\\\n",
    "            .select_dtypes(include=['number'])\\\n",
    "            .columns.tolist()\n",
    "        self.cat_cols = df.drop(columns=[target_col])\\\n",
    "            .select_dtypes(exclude=['number'])\\\n",
    "            .columns.tolist()\n",
    "        \n",
    "        # Fit numerical scaler\n",
    "        if self.num_cols:\n",
    "            self.num_scaler.fit(df[self.num_cols].fillna(0).values)\n",
    "        \n",
    "        # Fit categorical encoders and get cardinalities\n",
    "        self.cat_cardinalities = []\n",
    "        for col in self.cat_cols:\n",
    "            # Fill NA with a special category\n",
    "            series = df[col].fillna('__NA__').astype(str)\n",
    "            self.cat_encoders[col].fit(series)\n",
    "            self.cat_cardinalities.append(len(self.cat_encoders[col].classes_))\n",
    "        \n",
    "        self.fitted = True\n",
    "        return self\n",
    "    \n",
    "    def transform(self, df):\n",
    "        \"\"\"Transform a DataFrame into processed numerical and categorical tensors\"\"\"\n",
    "        if not self.fitted:\n",
    "            raise RuntimeError(\"Preprocessor must be fit before transforming data\")\n",
    "        \n",
    "        # Process numerical features\n",
    "        x_num = torch.empty(0)\n",
    "        if self.num_cols:\n",
    "            num_values = self.num_scaler.transform(df[self.num_cols].fillna(0).values)\n",
    "            x_num = torch.FloatTensor(num_values)\n",
    "        \n",
    "        # Process categorical features\n",
    "        x_cat = torch.empty(0)\n",
    "        if self.cat_cols:\n",
    "            cat_data = []\n",
    "            for col in self.cat_cols:\n",
    "                series = df[col].fillna('__NA__').astype(str)\n",
    "                encoded = self.cat_encoders[col].transform(series)\n",
    "                cat_data.append(encoded)\n",
    "            x_cat = torch.LongTensor(np.column_stack(cat_data))\n",
    "        \n",
    "        return x_num, x_cat\n",
    "    \n",
    "    def fit_transform(self, df):\n",
    "        \"\"\"Fit and transform in one step\"\"\"\n",
    "        return self.fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20ea4908",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabularDataset(Dataset):\n",
    "    \"\"\"Dataset for handling pandas DataFrames\"\"\"\n",
    "    def __init__(self, df, preprocessor, is_classification=True):\n",
    "        self.x_num, self.x_cat = preprocessor.transform(df)\n",
    "        self.is_classification = is_classification\n",
    "        # Convert to long for classification, float for regression\n",
    "        if is_classification:\n",
    "            self.y = torch.LongTensor(df['target'].values)  # Changed to LongTensor\n",
    "        else:\n",
    "            self.y = torch.FloatTensor(df['target'].values)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.x_cat.nelement() == 0:  # No categorical features\n",
    "            return self.x_num[idx], self.y[idx]\n",
    "        return self.x_num[idx], self.x_cat[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2744294",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, epochs=10, device='cpu'):\n",
    "    \"\"\"Training loop with validation\"\"\"\n",
    "    model.to(device)\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} - Training\"):\n",
    "            if len(batch) == 2:  # Only numerical features\n",
    "                x_num, y = batch\n",
    "                x_cat = None\n",
    "            else:  # Both numerical and categorical\n",
    "                x_num, x_cat, y = batch\n",
    "            \n",
    "            x_num = x_num.to(device)\n",
    "            y = y.to(device if model.num_classes is None else torch.long)  # Ensure correct type\n",
    "            if x_cat is not None:\n",
    "                x_cat = x_cat.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model.forward_from_processed(x_num, x_cat)\n",
    "            loss = criterion(outputs, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            train_loss += loss.item() * x_num.size(0)\n",
    "        \n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        all_preds = []\n",
    "        all_targets = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                if len(batch) == 2:\n",
    "                    x_num, y = batch\n",
    "                    x_cat = None\n",
    "                else:\n",
    "                    x_num, x_cat, y = batch\n",
    "                \n",
    "                x_num, y = x_num.to(device), y.to(device)\n",
    "                if x_cat is not None:\n",
    "                    x_cat = x_cat.to(device)\n",
    "                \n",
    "                outputs = model.forward_from_processed(x_num, x_cat)\n",
    "                loss = criterion(outputs, y)\n",
    "                val_loss += loss.item() * x_num.size(0)\n",
    "                \n",
    "                all_preds.append(outputs.cpu())\n",
    "                all_targets.append(y.cpu())\n",
    "        \n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        all_preds = torch.cat(all_preds)\n",
    "        all_targets = torch.cat(all_targets)\n",
    "        val_losses.append(val_loss)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        if model.num_classes is not None:  # Classification\n",
    "            preds = torch.argmax(all_preds, dim=1)\n",
    "            targets = all_targets.long()\n",
    "            accuracy = accuracy_score(targets, preds)\n",
    "            val_accuracies.append(accuracy)\n",
    "            print(f\"Epoch {epoch+1}: Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {accuracy:.4f}\")\n",
    "        else:  # Regression\n",
    "            rmse = mean_squared_error(all_targets, all_preds, squared=False)\n",
    "            print(f\"Epoch {epoch+1}: Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val RMSE: {rmse:.4f}\")\n",
    "            val_accuracies = None\n",
    "        \n",
    "        # Save best model\n",
    "        # if val_loss < best_val_loss:\n",
    "        #     best_val_loss = val_loss\n",
    "        #     torch.save(model.state_dict(), 'best_model.pth')\n",
    "    \n",
    "    print(\"Training complete!\")\n",
    "    # model.load_state_dict(torch.load('best_model.pth'))  # Load best model\n",
    "    return train_losses, val_losses, val_accuracies, model\n",
    "\n",
    "def predictions(model, df):\n",
    "    with torch.no_grad():\n",
    "        predictions_prob = model(df)\n",
    "        predictions = np.argmax(predictions_prob, axis=1)\n",
    "    df['prediction'] = predictions\n",
    "    return df\n",
    "\n",
    "def confusion_matrix(prediction_df):\n",
    "    y = prediction_df['target'].values\n",
    "    y_pred = prediction_df['prediction'].values\n",
    "    TP = FP = TN = FN = 0\n",
    "    for t, p in zip(y, y_pred):\n",
    "        TP += t == 1 and p == 1\n",
    "        FP += t == 0 and p == 1\n",
    "        TN += t == 0 and p == 0\n",
    "        FN += t == 1 and p == 0\n",
    "    return np.array([[TP, FP], [FN, TN]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6e2c3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "df['target'] = iris.target \n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d9b4b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "train_df, val_df = train_test_split(df_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocess data\n",
    "preprocessor = DataFramePreprocessor().fit(train_df)\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_dataset = TabularDataset(train_df, preprocessor)\n",
    "val_dataset = TabularDataset(val_df, preprocessor)\n",
    "\n",
    "batch_size = 4\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59658ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = FTTransformer(\n",
    "    preprocessor=preprocessor,\n",
    "    d_model=64,\n",
    "    nhead=4,\n",
    "    num_layers=3,\n",
    "    dim_feedforward=128,\n",
    "    dropout=0.1,\n",
    "    num_classes=4  # Binary classification\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6870b235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_tokenizer.cls_token                        64\n",
      "feature_tokenizer.num_projection.weight            256\n",
      "feature_tokenizer.num_projection.bias              64\n",
      "feature_tokenizer.norm.weight                      64\n",
      "feature_tokenizer.norm.bias                        64\n",
      "transformer_encoder.layers.0.self_attn.in_proj_weight 12,288\n",
      "transformer_encoder.layers.0.self_attn.in_proj_bias 192\n",
      "transformer_encoder.layers.0.self_attn.out_proj.weight 4,096\n",
      "transformer_encoder.layers.0.self_attn.out_proj.bias 64\n",
      "transformer_encoder.layers.0.linear1.weight        8,192\n",
      "transformer_encoder.layers.0.linear1.bias          128\n",
      "transformer_encoder.layers.0.linear2.weight        8,192\n",
      "transformer_encoder.layers.0.linear2.bias          64\n",
      "transformer_encoder.layers.0.norm1.weight          64\n",
      "transformer_encoder.layers.0.norm1.bias            64\n",
      "transformer_encoder.layers.0.norm2.weight          64\n",
      "transformer_encoder.layers.0.norm2.bias            64\n",
      "transformer_encoder.layers.1.self_attn.in_proj_weight 12,288\n",
      "transformer_encoder.layers.1.self_attn.in_proj_bias 192\n",
      "transformer_encoder.layers.1.self_attn.out_proj.weight 4,096\n",
      "transformer_encoder.layers.1.self_attn.out_proj.bias 64\n",
      "transformer_encoder.layers.1.linear1.weight        8,192\n",
      "transformer_encoder.layers.1.linear1.bias          128\n",
      "transformer_encoder.layers.1.linear2.weight        8,192\n",
      "transformer_encoder.layers.1.linear2.bias          64\n",
      "transformer_encoder.layers.1.norm1.weight          64\n",
      "transformer_encoder.layers.1.norm1.bias            64\n",
      "transformer_encoder.layers.1.norm2.weight          64\n",
      "transformer_encoder.layers.1.norm2.bias            64\n",
      "transformer_encoder.layers.2.self_attn.in_proj_weight 12,288\n",
      "transformer_encoder.layers.2.self_attn.in_proj_bias 192\n",
      "transformer_encoder.layers.2.self_attn.out_proj.weight 4,096\n",
      "transformer_encoder.layers.2.self_attn.out_proj.bias 64\n",
      "transformer_encoder.layers.2.linear1.weight        8,192\n",
      "transformer_encoder.layers.2.linear1.bias          128\n",
      "transformer_encoder.layers.2.linear2.weight        8,192\n",
      "transformer_encoder.layers.2.linear2.bias          64\n",
      "transformer_encoder.layers.2.norm1.weight          64\n",
      "transformer_encoder.layers.2.norm1.bias            64\n",
      "transformer_encoder.layers.2.norm2.weight          64\n",
      "transformer_encoder.layers.2.norm2.bias            64\n",
      "head.weight                                        256\n",
      "head.bias                                          4\n",
      "\n",
      "Total trainable parameters: 101,188\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"{name:50s} {param.numel():,}\")\n",
    "        total += param.numel()\n",
    "\n",
    "print(f\"\\nTotal trainable parameters: {total:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8276eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up training\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "criterion = nn.CrossEntropyLoss()  # For multi-class classification\n",
    "# criterion = nn.MSELoss()  # For regression\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=1e-4,          \n",
    "    weight_decay=1e-2\n",
    ")\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.LinearLR(\n",
    "    optimizer,\n",
    "    start_factor=0.1,\n",
    "    total_iters=5   \n",
    ")\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a59d1623",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Training: 100%|██████████| 24/24 [00:00<00:00, 102.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 1.6307, Val Loss: 0.9043, Val Acc: 0.5417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 - Training: 100%|██████████| 24/24 [00:00<00:00, 108.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss: 0.6482, Val Loss: 0.5082, Val Acc: 0.7500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 - Training: 100%|██████████| 24/24 [00:00<00:00, 94.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss: 0.5239, Val Loss: 0.3989, Val Acc: 0.8333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 - Training: 100%|██████████| 24/24 [00:00<00:00, 101.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss: 0.5252, Val Loss: 0.4085, Val Acc: 0.7917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 - Training: 100%|██████████| 24/24 [00:00<00:00, 100.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss: 0.4392, Val Loss: 0.3747, Val Acc: 0.8750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 - Training: 100%|██████████| 24/24 [00:00<00:00, 103.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss: 0.3781, Val Loss: 0.3502, Val Acc: 0.8750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 - Training: 100%|██████████| 24/24 [00:00<00:00, 80.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss: 0.3721, Val Loss: 0.3362, Val Acc: 0.8750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 - Training: 100%|██████████| 24/24 [00:00<00:00, 102.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss: 0.3921, Val Loss: 0.3542, Val Acc: 0.8750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 - Training: 100%|██████████| 24/24 [00:00<00:00, 105.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss: 0.4591, Val Loss: 0.3397, Val Acc: 0.8750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 - Training: 100%|██████████| 24/24 [00:00<00:00, 104.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Loss: 0.4425, Val Loss: 0.2992, Val Acc: 0.9167\n",
      "Training complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "train_loss, val_loss, val_acc, trained_model = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    epochs=epochs,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b987551d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines+markers",
         "name": "Train Loss",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "y": [
          1.6306593418121338,
          0.6482117758132517,
          0.5238954114417235,
          0.525249982252717,
          0.4391826080779235,
          0.37805583343530696,
          0.37208009511232376,
          0.3920789600815624,
          0.45906908142690855,
          0.4425037013522039
         ],
         "yaxis": "y"
        },
        {
         "mode": "lines+markers",
         "name": "Validation Loss",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "y": [
          0.9042653640111288,
          0.5082466701666514,
          0.398945190012455,
          0.40854765971501666,
          0.37468283375104267,
          0.35020962978402775,
          0.3362401680399974,
          0.3541582121203343,
          0.33970107448597747,
          0.29920101910829544
         ],
         "yaxis": "y"
        },
        {
         "mode": "lines+markers",
         "name": "Validation Accuracy",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "y": [
          0.5416666666666666,
          0.75,
          0.8333333333333334,
          0.7916666666666666,
          0.875,
          0.875,
          0.875,
          0.875,
          0.875,
          0.9166666666666666
         ],
         "yaxis": "y2"
        }
       ],
       "layout": {
        "legend": {
         "x": 0.01,
         "y": 0.99
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Training & Validation Loss with Validation Accuracy"
        },
        "xaxis": {
         "title": {
          "text": "Epoch"
         }
        },
        "yaxis": {
         "side": "left",
         "title": {
          "text": "Loss"
         }
        },
        "yaxis2": {
         "overlaying": "y",
         "range": [
          0,
          1
         ],
         "side": "right",
         "title": {
          "text": "Accuracy"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "epochs_range = list(range(1, len(train_loss) + 1))\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# Train loss\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=epochs_range,\n",
    "    y=train_loss,\n",
    "    mode='lines+markers',\n",
    "    name='Train Loss',\n",
    "    yaxis='y1'\n",
    "))\n",
    "\n",
    "# Validation loss\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=epochs_range,\n",
    "    y=val_loss,\n",
    "    mode='lines+markers',\n",
    "    name='Validation Loss',\n",
    "    yaxis='y1'\n",
    "))\n",
    "\n",
    "# Validation accuracy (secondary axis)\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=epochs_range,\n",
    "    y=val_acc,\n",
    "    mode='lines+markers',\n",
    "    name='Validation Accuracy',\n",
    "    yaxis='y2'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Training & Validation Loss with Validation Accuracy',\n",
    "    xaxis_title='Epoch',\n",
    "    yaxis=dict(\n",
    "        title='Loss',\n",
    "        side='left'\n",
    "    ),\n",
    "    yaxis2=dict(\n",
    "        title='Accuracy',\n",
    "        overlaying='y',\n",
    "        side='right',\n",
    "        range=[0, 1]\n",
    "    ),\n",
    "    legend=dict(x=0.01, y=0.99),\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7aacb50c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7,  0],\n",
       "       [ 0, 10]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = predictions(trained_model, df_test)\n",
    "confusion_matrix(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a27486",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
