{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "runtime_attributes": {
        "runtime_version": "2025.10"
      },
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## SASRec with Explanation"
      ],
      "metadata": {
        "id": "XhebkPsN3pEJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7wmq5Ulc3iZd"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import random\n",
        "from collections import defaultdict\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from itertools import combinations\n",
        "from numpy.linalg import norm\n",
        "import os\n",
        "import zipfile\n",
        "import requests"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CFG = {\n",
        "    \"MAX_LEN\": 50,\n",
        "    \"HIDDEN\": 128,\n",
        "    \"N_LAYERS\": 2,\n",
        "    \"N_HEADS\": 4,\n",
        "    \"DROPOUT\": 0.2,\n",
        "    \"LR\": 3e-4,\n",
        "    \"BATCH_SIZE\": 256,\n",
        "    \"EPOCHS\": 20,\n",
        "    \"MASK_PROB\": 0.15,\n",
        "    \"NEG_SAMPLES\": 100,\n",
        "    \"MIN_INTERACTIONS\": 5,\n",
        "    \"DEVICE\": \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "}\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed()"
      ],
      "metadata": {
        "id": "68emGRuj3xwZ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## load_and_prepare\n",
        "**What happens here?**\n",
        "\n",
        "- Reads interaction dataset (like MovieLens).\n",
        "- Sorts interactions by:\n",
        "\n",
        "  - userId\n",
        "  - timestamp\n",
        "\n",
        "**Why sorting is important?**\n",
        "\n",
        "Because SASRec is a sequential model.\n",
        "The order of interactions must reflect real user behavior timeline.\n",
        "\n",
        "If not sorted â†’ sequence becomes meaningless."
      ],
      "metadata": {
        "id": "WAVAb9cq4hVK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PAD_TOKEN = 0\n",
        "MASK_TOKEN = 1\n",
        "\n",
        "def load_and_prepare(df):\n",
        "\n",
        "    df = df.sort_values([\"userId\", \"timestamp\"])\n",
        "\n",
        "    user2seq = defaultdict(list)\n",
        "\n",
        "    for row in df.itertuples():\n",
        "        user2seq[row.userId].append(row.movieId)\n",
        "\n",
        "    # Filter short users\n",
        "    user2seq = {\n",
        "        u: seq for u, seq in user2seq.items()\n",
        "        if len(seq) >= CFG[\"MIN_INTERACTIONS\"]\n",
        "    }\n",
        "\n",
        "    # Remap items\n",
        "    valid_user_ids = set(user2seq.keys())\n",
        "\n",
        "    item_set = set(\n",
        "        df[df[\"userId\"].isin(valid_user_ids)][\"movieId\"].unique()\n",
        "    )\n",
        "\n",
        "    item2id = {item: idx+2 for idx, item in enumerate(item_set)}\n",
        "    id2item = {v: k for k, v in item2id.items()}\n",
        "    vocab_size = len(item2id) + 2\n",
        "\n",
        "    remapped_sequences = {\n",
        "        u: [item2id[i] for i in seq]\n",
        "        for u, seq in user2seq.items()\n",
        "    }\n",
        "\n",
        "    print(f\"Total users: {len(remapped_sequences)}\")\n",
        "    print(f\"Total items: {len(item2id)}\")\n",
        "    print(f\"Vocab size (including PAD & MASK): {vocab_size}\")\n",
        "\n",
        "    return remapped_sequences, vocab_size, item2id, id2item"
      ],
      "metadata": {
        "id": "fob953YY30Gv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For each user, If sequence is:\n",
        "```\n",
        "[ i1, i2, i3, i4, i5 ]\n",
        "```\n",
        "Then:\n",
        "```\n",
        "train = [i1, i2, i3]\n",
        "val   = i4\n",
        "test  = i5\n",
        "```\n",
        "This is called leave-one-out chronological split. Because this is a sequential recommendation problem, random split will leads to data leakage."
      ],
      "metadata": {
        "id": "o6yfmyQ3LfFA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_sequences(user_sequences):\n",
        "\n",
        "    train, val, test = {}, {}, {}\n",
        "\n",
        "    for u, seq in user_sequences.items():\n",
        "        train[u] = seq[:-2]\n",
        "        val[u]   = seq[-2]\n",
        "        test[u]  = seq[-1]\n",
        "\n",
        "    return train, val, test"
      ],
      "metadata": {
        "id": "2mzSZimZLexe"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Why we need `sample_negative`?\n",
        "In implicit-feedback recommendation, we only observe positive interactions\n",
        "$(u, i^+)$ (e.g., a user watched a movie in MovieLens), but we do not observe explicit negatives. To learn a ranking function $f(u,i)$ that orders items correctly, the model must satisfy $f(u,i^+)>f(u,i^âˆ’)$ for items $i^âˆ’$ the user did not interact with. However, without negative samples, optimizing only $f(u,i^+)$ leads to a trivial solution where the model increases scores for all items, failing to learn meaningful preferences. By sampling a negative item $ð‘–^âˆ’ âˆ‰ ð‘†_ð‘¢$ (the userâ€™s interaction set), we can define a pairwise ranking loss such as Bayesian Personalized Ranking (BPR):\n",
        "\n",
        "$$\n",
        "ð¿=-âˆ‘_{(u, i^+,i^-)} log~Ïƒ(f(u,i^+)-f(u,i^âˆ’))\n",
        "$$\n",
        "\n",
        "which explicitly enforces relative ordering. Thus, negative sampling is mathematically necessary to transform positive-only implicit data into a comparative learning objective that produces a discriminative ranking model."
      ],
      "metadata": {
        "id": "LT-xWAhTNB-2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SASRecDataset(Dataset):\n",
        "\n",
        "    def __init__(self, user_sequences, vocab_size):\n",
        "        self.users = list(user_sequences.keys())\n",
        "        self.user_sequences = user_sequences\n",
        "        self.vocab_size = vocab_size\n",
        "\n",
        "    def sample_negative(self, pos_item, user_seq):\n",
        "        while True:\n",
        "            neg = random.randint(2, self.vocab_size-1)\n",
        "            if neg not in user_seq:\n",
        "                return neg\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        user = self.users[idx]\n",
        "        seq = self.user_sequences[user][-CFG[\"MAX_LEN\"]:]\n",
        "\n",
        "        padding = CFG[\"MAX_LEN\"] - len(seq)\n",
        "        seq = [PAD_TOKEN]*padding + seq\n",
        "\n",
        "        pos_item = seq[-1]\n",
        "        neg_item = self.sample_negative(pos_item, seq)\n",
        "\n",
        "        attention_mask = torch.tensor(seq) != PAD_TOKEN\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": torch.tensor(seq),\n",
        "            \"attention_mask\": attention_mask.bool(),\n",
        "            \"pos_item\": torch.tensor(pos_item),\n",
        "            \"neg_item\": torch.tensor(neg_item)\n",
        "        }\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.users)"
      ],
      "metadata": {
        "id": "sGfxQEatPz2k"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model\n",
        "### High-Level Idea\n",
        "\n",
        "The model:\n",
        "- Converts item IDs â†’ embeddings\n",
        "- Adds positional information\n",
        "- Passes sequence through Transformer encoder\n",
        "- Returns representation of last position\n",
        "- That representation is later used for ranking\n",
        "\n",
        "So conceptually:\n",
        "\n",
        "User Sequence â†’ Contextual Representation â†’ Score Items\n",
        "\n",
        "We get the user embedding from:\n",
        "```\n",
        "x[:, -1, :]\n",
        "```\n",
        "This is the contextual representation of the entire interaction sequence.\n",
        "\n",
        "Then score is computed as:\n",
        "$$\n",
        "score(u,i)=u^Te_i\n",
        "$$\n",
        "\n",
        "\n",
        "where:\n",
        "- $u$ = final transformer output (dynamic user embedding)\n",
        "- $e_i$ = item embedding from embedding table (`self.item_emb = nn.Embedding(vocab_size, hidden_dim)`)"
      ],
      "metadata": {
        "id": "Y1zgZ6qnRElZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SASRec(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size):\n",
        "        super().__init__()\n",
        "\n",
        "        self.item_emb = nn.Embedding(vocab_size, CFG[\"HIDDEN\"], padding_idx=PAD_TOKEN)\n",
        "        self.pos_emb  = nn.Embedding(CFG[\"MAX_LEN\"], CFG[\"HIDDEN\"])\n",
        "\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=CFG[\"HIDDEN\"],\n",
        "            nhead=CFG[\"N_HEADS\"],\n",
        "            dim_feedforward=CFG[\"HIDDEN\"]*4,\n",
        "            dropout=CFG[\"DROPOUT\"],\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        self.encoder = nn.TransformerEncoder(encoder_layer, CFG[\"N_LAYERS\"])\n",
        "        self.layer_norm = nn.LayerNorm(CFG[\"HIDDEN\"])\n",
        "        self.dropout = nn.Dropout(CFG[\"DROPOUT\"])\n",
        "\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        for p in self.parameters():\n",
        "            if p.dim() > 1:\n",
        "                nn.init.xavier_uniform_(p)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "\n",
        "        positions = torch.arange(0, input_ids.size(1),\n",
        "                                 device=input_ids.device).unsqueeze(0)\n",
        "\n",
        "        x = self.item_emb(input_ids) + self.pos_emb(positions)\n",
        "        x = self.layer_norm(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.encoder(x, src_key_padding_mask=~attention_mask)\n",
        "\n",
        "        return x[:, -1, :]  # final representation"
      ],
      "metadata": {
        "id": "yfXSY5hPRFt2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bpr_loss(user_repr, pos_emb, neg_emb):\n",
        "\n",
        "    pos_score = torch.sum(user_repr * pos_emb, dim=1)\n",
        "    neg_score = torch.sum(user_repr * neg_emb, dim=1)\n",
        "\n",
        "    return -torch.mean(F.logsigmoid(pos_score - neg_score))"
      ],
      "metadata": {
        "id": "Dhn-sHiQVBCr"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, dataloader, optimizer):\n",
        "\n",
        "    model.train()\n",
        "    scaler = torch.cuda.amp.GradScaler()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in tqdm(dataloader):\n",
        "\n",
        "        input_ids = batch[\"input_ids\"].to(CFG[\"DEVICE\"])\n",
        "        mask = batch[\"attention_mask\"].to(CFG[\"DEVICE\"])\n",
        "        pos_item = batch[\"pos_item\"].to(CFG[\"DEVICE\"])\n",
        "        neg_item = batch[\"neg_item\"].to(CFG[\"DEVICE\"])\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with torch.cuda.amp.autocast():\n",
        "\n",
        "            user_repr = model(input_ids, mask)\n",
        "\n",
        "            pos_emb = model.item_emb(pos_item)\n",
        "            neg_emb = model.item_emb(neg_item)\n",
        "\n",
        "            loss = bpr_loss(user_repr, pos_emb, neg_emb)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)"
      ],
      "metadata": {
        "id": "daT7W1EsU_he"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(\n",
        "    model,\n",
        "    train_seq,\n",
        "    eval_target,\n",
        "    total_items,\n",
        "    item_embeddings=None,   # optional for diversity\n",
        "    k=10,\n",
        "    neg_samples=100,\n",
        "    max_len=50,\n",
        "    pad_token=0,\n",
        "    device=\"cuda\"\n",
        "):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    HR, NDCG, RECALL, MRR, PRECISION = [], [], [], [], []\n",
        "    all_recommendations = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for u in train_seq:\n",
        "\n",
        "            # -----------------------------\n",
        "            # Prepare sequence\n",
        "            # -----------------------------\n",
        "            seq = train_seq[u][-max_len:]\n",
        "            seq = [pad_token] * (max_len - len(seq)) + seq\n",
        "\n",
        "            input_ids = torch.tensor(seq).unsqueeze(0).to(device)\n",
        "            mask = (input_ids != pad_token)  # Proper boolean mask\n",
        "\n",
        "            # -----------------------------\n",
        "            # Forward pass\n",
        "            # -----------------------------\n",
        "            user_repr = model(input_ids, mask)  # (1, hidden_dim)\n",
        "\n",
        "            # -----------------------------\n",
        "            # Candidate sampling\n",
        "            # -----------------------------\n",
        "            true_item = eval_target[u]\n",
        "\n",
        "            candidates = random.sample(\n",
        "                range(2, model.item_emb.num_embeddings),\n",
        "                neg_samples\n",
        "            )\n",
        "\n",
        "            if true_item not in candidates:\n",
        "                candidates.append(true_item)\n",
        "\n",
        "            item_tensor = torch.tensor(candidates).to(device)\n",
        "            item_embs = model.item_emb(item_tensor)\n",
        "\n",
        "            # Dot-product scoring\n",
        "            scores = torch.matmul(user_repr, item_embs.T).squeeze(0)\n",
        "\n",
        "            # -----------------------------\n",
        "            # Top-K ranking\n",
        "            # -----------------------------\n",
        "            topk_idx = torch.topk(scores, k).indices.cpu().numpy()\n",
        "            ranked_items = [candidates[i] for i in topk_idx]\n",
        "\n",
        "            all_recommendations.append(ranked_items)\n",
        "\n",
        "            # -----------------------------\n",
        "            # Metrics\n",
        "            # -----------------------------\n",
        "            gt = {true_item}\n",
        "\n",
        "            # HR\n",
        "            hit = int(true_item in ranked_items)\n",
        "            HR.append(hit)\n",
        "\n",
        "            # NDCG\n",
        "            if hit:\n",
        "                rank = ranked_items.index(true_item)\n",
        "                NDCG.append(1 / np.log2(rank + 2))\n",
        "            else:\n",
        "                NDCG.append(0.0)\n",
        "\n",
        "            # Precision@K\n",
        "            PRECISION.append(hit / k)\n",
        "\n",
        "            # Recall\n",
        "            RECALL.append(hit)  # single ground truth â†’ same as HR\n",
        "\n",
        "            # MRR\n",
        "            if hit:\n",
        "                MRR.append(1.0 / (rank + 1))\n",
        "            else:\n",
        "                MRR.append(0.0)\n",
        "\n",
        "    # ---------------------------------\n",
        "    # Coverage\n",
        "    # ---------------------------------\n",
        "    recommended_items = set()\n",
        "    for ranked in all_recommendations:\n",
        "        recommended_items.update(ranked)\n",
        "\n",
        "    coverage = len(recommended_items) / total_items\n",
        "\n",
        "    # ---------------------------------\n",
        "    # Diversity (optional)\n",
        "    # ---------------------------------\n",
        "    diversity_scores = []\n",
        "\n",
        "    if item_embeddings is not None:\n",
        "        for ranked in all_recommendations:\n",
        "\n",
        "            if len(ranked) < 2:\n",
        "                diversity_scores.append(0.0)\n",
        "                continue\n",
        "\n",
        "            vectors = item_embeddings[ranked]\n",
        "\n",
        "            total_sim = 0.0\n",
        "            count = 0\n",
        "\n",
        "            for i, j in combinations(range(len(vectors)), 2):\n",
        "                sim = np.dot(vectors[i], vectors[j]) / (\n",
        "                    norm(vectors[i]) * norm(vectors[j]) + 1e-8\n",
        "                )\n",
        "                total_sim += (1 - sim)\n",
        "                count += 1\n",
        "\n",
        "            diversity_scores.append(total_sim / count)\n",
        "\n",
        "        diversity = np.mean(diversity_scores)\n",
        "    else:\n",
        "        diversity = None\n",
        "\n",
        "    # ---------------------------------\n",
        "    # Final results\n",
        "    # ---------------------------------\n",
        "    return {\n",
        "        \"HR@{}\".format(k): np.mean(HR),\n",
        "        \"Precision@{}\".format(k): np.mean(PRECISION),\n",
        "        \"NDCG@{}\".format(k): np.mean(NDCG),\n",
        "        \"Recall@{}\".format(k): np.mean(RECALL),\n",
        "        \"MRR@{}\".format(k): np.mean(MRR),\n",
        "        \"Coverage@{}\".format(k): coverage,\n",
        "        \"Diversity@{}\".format(k): diversity\n",
        "    }\n"
      ],
      "metadata": {
        "id": "h__53of0alJ2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# CONFIG\n",
        "# ================================\n",
        "\n",
        "DATASET_NAME = \"ml-25m\"  # change if needed: ml-latest-small\n",
        "BASE_URL = \"https://files.grouplens.org/datasets/movielens/\"\n",
        "DOWNLOAD_URL = f\"{BASE_URL}{DATASET_NAME}.zip\"\n",
        "SAVE_PATH = \"./data\"\n",
        "\n",
        "# ================================\n",
        "# STEP 1: Download Dataset\n",
        "# ================================\n",
        "\n",
        "def download_movielens():\n",
        "    os.makedirs(SAVE_PATH, exist_ok=True)\n",
        "    zip_path = os.path.join(SAVE_PATH, f\"{DATASET_NAME}.zip\")\n",
        "\n",
        "    if not os.path.exists(zip_path):\n",
        "        print(\"Downloading dataset...\")\n",
        "        response = requests.get(DOWNLOAD_URL)\n",
        "        with open(zip_path, \"wb\") as f:\n",
        "            f.write(response.content)\n",
        "        print(\"Download complete.\")\n",
        "    else:\n",
        "        print(\"Dataset already downloaded.\")\n",
        "\n",
        "    return zip_path\n",
        "\n",
        "\n",
        "# ================================\n",
        "# STEP 2: Extract\n",
        "# ================================\n",
        "\n",
        "def extract_dataset(zip_path):\n",
        "    extract_path = os.path.join(SAVE_PATH, DATASET_NAME)\n",
        "\n",
        "    if not os.path.exists(extract_path):\n",
        "        print(\"Extracting dataset...\")\n",
        "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(SAVE_PATH)\n",
        "        print(\"Extraction complete.\")\n",
        "    else:\n",
        "        print(\"Dataset already extracted.\")\n",
        "\n",
        "    return extract_path\n",
        "\n",
        "\n",
        "# ================================\n",
        "# STEP 3: Load ratings.csv\n",
        "# ================================\n",
        "\n",
        "def load_ratings(extract_path):\n",
        "    ratings_path = os.path.join(extract_path, \"ratings.csv\")\n",
        "\n",
        "    print(\"Loading ratings...\")\n",
        "    df = pd.read_csv(ratings_path)\n",
        "\n",
        "    # Sort by user and timestamp\n",
        "    df = df.sort_values([\"userId\", \"timestamp\"])\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "# ================================\n",
        "# FULL PIPELINE FUNCTION\n",
        "# ================================\n",
        "\n",
        "def prepare_movielens():\n",
        "    zip_path = download_movielens()\n",
        "    extract_path = extract_dataset(zip_path)\n",
        "    df = load_ratings(extract_path)\n",
        "\n",
        "    user_sequences, vocab_size, item2id, id2item = load_and_prepare(df)\n",
        "\n",
        "    return user_sequences, vocab_size, item2id, id2item"
      ],
      "metadata": {
        "id": "CljyO44ZiBTq"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_sequences, vocab_size, item2id, id2item = prepare_movielens()\n",
        "train_seq, val_seq, test_seq = split_sequences(user_sequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmDZLGMCif3d",
        "outputId": "88b6deee-c6e8-4f66-e447-58c28d88e1ec"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading dataset...\n",
            "Download complete.\n",
            "Extracting dataset...\n",
            "Extraction complete.\n",
            "Loading ratings...\n",
            "Total users: 162541\n",
            "Total items: 59047\n",
            "Vocab size (including PAD & MASK): 59049\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = SASRecDataset(train_seq, vocab_size)\n",
        "train_loader = DataLoader(train_dataset,\n",
        "                          batch_size=CFG[\"BATCH_SIZE\"],\n",
        "                          shuffle=True,\n",
        "                          num_workers=4)\n",
        "\n",
        "model = SASRec(vocab_size).to(CFG[\"DEVICE\"])\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=CFG[\"LR\"])\n",
        "\n",
        "for epoch in range(CFG[\"EPOCHS\"]):\n",
        "\n",
        "    # -----------------------\n",
        "    # Train\n",
        "    # -----------------------\n",
        "    loss = train(model, train_loader, optimizer)\n",
        "\n",
        "    # -----------------------\n",
        "    # Evaluate\n",
        "    # -----------------------\n",
        "    metrics = evaluate(\n",
        "        model=model,\n",
        "        train_seq=train_seq,\n",
        "        eval_target=val_seq,\n",
        "        total_items=vocab_size,\n",
        "        item_embeddings=model.item_emb.weight.detach().cpu().numpy(),\n",
        "        k=10,\n",
        "        neg_samples=CFG[\"NEG_SAMPLES\"],\n",
        "        max_len=CFG[\"MAX_LEN\"],\n",
        "        pad_token=PAD_TOKEN,\n",
        "        device=CFG[\"DEVICE\"]\n",
        "    )\n",
        "\n",
        "    # -----------------------\n",
        "    # Logging\n",
        "    # -----------------------\n",
        "    print(f\"\\nEpoch {epoch+1}\")\n",
        "    print(f\"Loss: {loss:.4f}\")\n",
        "\n",
        "    print(f\"HR@10: {metrics['HR@10']:.4f}\")\n",
        "    print(f\"NDCG@10: {metrics['NDCG@10']:.4f}\")\n",
        "    print(f\"Recall@10: {metrics['Recall@10']:.4f}\")\n",
        "    print(f\"MRR@10: {metrics['MRR@10']:.4f}\")\n",
        "    print(f\"Coverage@10: {metrics['Coverage@10']:.4f}\")\n",
        "\n",
        "    if metrics[\"Diversity@10\"] is not None:\n",
        "        print(f\"Diversity@10: {metrics['Diversity@10']:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "Slm6w_1Rh6T8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "365ed020-3ab4-4735-a709-3719d0a179b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-3867157008.py:4: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler()\n",
            "  0%|          | 0/635 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-3867157008.py:16: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 635/635 [00:19<00:00, 31.97it/s]\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:515: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. We recommend specifying layout=torch.jagged when constructing a nested tensor, as this layout receives active development, has better operator coverage, and works with torch.compile. (Triggered internally at /pytorch/aten/src/ATen/NestedTensorImpl.cpp:178.)\n",
            "  output = torch._nested_tensor_from_mask(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1\n",
            "Loss: 0.2811\n",
            "HR@10: 0.9274\n",
            "NDCG@10: 0.6612\n",
            "Recall@10: 0.9274\n",
            "MRR@10: 0.5760\n",
            "Coverage@10: 0.1900\n",
            "Diversity@10: 0.4356\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 635/635 [00:16<00:00, 37.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2\n",
            "Loss: 0.0871\n",
            "HR@10: 0.9255\n",
            "NDCG@10: 0.6559\n",
            "Recall@10: 0.9255\n",
            "MRR@10: 0.5698\n",
            "Coverage@10: 0.3228\n",
            "Diversity@10: 0.3596\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 635/635 [00:17<00:00, 37.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 3\n",
            "Loss: 0.0510\n",
            "HR@10: 0.9276\n",
            "NDCG@10: 0.6544\n",
            "Recall@10: 0.9276\n",
            "MRR@10: 0.5672\n",
            "Coverage@10: 0.2711\n",
            "Diversity@10: 0.3964\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 635/635 [00:17<00:00, 37.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 4\n",
            "Loss: 0.0335\n",
            "HR@10: 0.9282\n",
            "NDCG@10: 0.6537\n",
            "Recall@10: 0.9282\n",
            "MRR@10: 0.5660\n",
            "Coverage@10: 0.2179\n",
            "Diversity@10: 0.4398\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 635/635 [00:17<00:00, 35.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 5\n",
            "Loss: 0.0216\n",
            "HR@10: 0.9273\n",
            "NDCG@10: 0.6495\n",
            "Recall@10: 0.9273\n",
            "MRR@10: 0.5610\n",
            "Coverage@10: 0.2094\n",
            "Diversity@10: 0.4861\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 635/635 [00:17<00:00, 37.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 6\n",
            "Loss: 0.0129\n",
            "HR@10: 0.9257\n",
            "NDCG@10: 0.6437\n",
            "Recall@10: 0.9257\n",
            "MRR@10: 0.5538\n",
            "Coverage@10: 0.2076\n",
            "Diversity@10: 0.5281\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 635/635 [00:16<00:00, 38.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 7\n",
            "Loss: 0.0078\n",
            "HR@10: 0.9240\n",
            "NDCG@10: 0.6330\n",
            "Recall@10: 0.9240\n",
            "MRR@10: 0.5405\n",
            "Coverage@10: 0.2030\n",
            "Diversity@10: 0.5658\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 635/635 [00:17<00:00, 37.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 8\n",
            "Loss: 0.0046\n",
            "HR@10: 0.9210\n",
            "NDCG@10: 0.6244\n",
            "Recall@10: 0.9210\n",
            "MRR@10: 0.5304\n",
            "Coverage@10: 0.2016\n",
            "Diversity@10: 0.5992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 635/635 [00:17<00:00, 35.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 9\n",
            "Loss: 0.0027\n",
            "HR@10: 0.9162\n",
            "NDCG@10: 0.6099\n",
            "Recall@10: 0.9162\n",
            "MRR@10: 0.5131\n",
            "Coverage@10: 0.2042\n",
            "Diversity@10: 0.6310\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 635/635 [00:16<00:00, 37.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 10\n",
            "Loss: 0.0015\n",
            "HR@10: 0.9122\n",
            "NDCG@10: 0.6009\n",
            "Recall@10: 0.9122\n",
            "MRR@10: 0.5028\n",
            "Coverage@10: 0.1997\n",
            "Diversity@10: 0.6560\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 635/635 [00:17<00:00, 36.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 11\n",
            "Loss: 0.0009\n",
            "HR@10: 0.9031\n",
            "NDCG@10: 0.5853\n",
            "Recall@10: 0.9031\n",
            "MRR@10: 0.4855\n",
            "Coverage@10: 0.2017\n",
            "Diversity@10: 0.6808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 635/635 [00:16<00:00, 37.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 12\n",
            "Loss: 0.0005\n",
            "HR@10: 0.8954\n",
            "NDCG@10: 0.5727\n",
            "Recall@10: 0.8954\n",
            "MRR@10: 0.4717\n",
            "Coverage@10: 0.2012\n",
            "Diversity@10: 0.7017\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 635/635 [00:17<00:00, 35.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 13\n",
            "Loss: 0.0003\n",
            "HR@10: 0.8877\n",
            "NDCG@10: 0.5613\n",
            "Recall@10: 0.8877\n",
            "MRR@10: 0.4594\n",
            "Coverage@10: 0.1996\n",
            "Diversity@10: 0.7202\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 635/635 [00:16<00:00, 37.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 14\n",
            "Loss: 0.0002\n",
            "HR@10: 0.8691\n",
            "NDCG@10: 0.5409\n",
            "Recall@10: 0.8691\n",
            "MRR@10: 0.4387\n",
            "Coverage@10: 0.2021\n",
            "Diversity@10: 0.7391\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 635/635 [00:17<00:00, 36.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 15\n",
            "Loss: 0.0001\n",
            "HR@10: 0.8599\n",
            "NDCG@10: 0.5295\n",
            "Recall@10: 0.8599\n",
            "MRR@10: 0.4270\n",
            "Coverage@10: 0.2012\n",
            "Diversity@10: 0.7537\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 635/635 [00:16<00:00, 38.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 16\n",
            "Loss: 0.0001\n",
            "HR@10: 0.8376\n",
            "NDCG@10: 0.5085\n",
            "Recall@10: 0.8376\n",
            "MRR@10: 0.4068\n",
            "Coverage@10: 0.2044\n",
            "Diversity@10: 0.7697\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 635/635 [00:18<00:00, 35.17it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w8uPWO-jfos7"
      },
      "execution_count": 11,
      "outputs": []
    }
  ]
}